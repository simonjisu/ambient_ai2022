{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import math\n",
    "from datetime import datetime as dt\n",
    "import moviepy\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, ImageClip, TextClip, VideoClip, concatenate_videoclips, clips_array\n",
    "from tqdm import tqdm\n",
    "print(moviepy.__version__)\n",
    "data_path = Path('.').resolve() / 'videos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(data_path):\n",
    "    x = dict()\n",
    "    for i, (p, name, kor_name) in enumerate(zip(\n",
    "            data_path.glob('*.mp4'), \n",
    "            ['hipjoint', 'shoulder', 'waist', 'trapezius'], \n",
    "            ['고관절', '어깨', '허리디스크', '승모근']\n",
    "        )):\n",
    "        pname = p.name.rstrip('.mp4')\n",
    "        new_name = f'{i:02d}_{name}'\n",
    "        x[new_name] = {'video_name': pname, 'kor_name': kor_name}\n",
    "        p.rename(data_path / f'{new_name}.mp4')\n",
    "    with (data_path / 'video_names.json').open('w') as file:\n",
    "        json.dump(x, file)\n",
    "\n",
    "# rename_files(data_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "수정사항\n",
    "* 영상을 살펴보니 00_hipjoint는 두 개의 동작이 있음\n",
    "* 각 영상에는 설명부분과 운동하는 부분이 있음 > 영상 잘라야 할 필요성 있음\n",
    "* 한 부위에 대해서 두 가지 방법을 알려주기도 함\n",
    "\n",
    "영상 \n",
    "* 우선 설명 보고 > 동작 3회 반복\n",
    "\n",
    "1. `00_hipjoint.mp4`\n",
    "    * `00:22`: 설명\n",
    "    * `00:18.20-00:22.97`: 동작1 (15회 반복)\n",
    "    * ~~`00:25-00:38`: 설명~~\n",
    "    * ~~`00:33.11-00:39.98`: 동작2 (15회 반복) ~~\n",
    "2. `01_shoulder.mp4`\n",
    "    * `00:22-00:26`: 동작 (15회 5세트)\n",
    "3. `02_waist.mp4`\n",
    "    * `00:20-00:23`: 동작1 (12회)\n",
    "    * `00:36-00:38`: 동작2 (12회), alternative\n",
    "4. `03_trapezius.mp4`\n",
    "    * `00:17-00:19`: 동작1 (10회)\n",
    "    * `00:21-00:22`: 동작2 (10회)\n",
    "\n",
    "https://zulko.github.io/moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MP_DRAWING = mp.solutions.drawing_utils\n",
    "MP_DRAWING_STYLE = mp.solutions.drawing_styles\n",
    "MP_POSE = mp.solutions.pose\n",
    "\n",
    "def calculate_angle(a, b, c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle > 180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle \n",
    "\n",
    "def process_mediapipe(image):\n",
    "    img_w, img_h, _ = image.shape\n",
    "    with MP_POSE.Pose(\n",
    "            min_detection_confidence=0.5, \n",
    "            min_tracking_confidence=0.5, \n",
    "            model_complexity=2, \n",
    "            enable_segmentation=True\n",
    "        ) as POSE:\n",
    "        # Make detection\n",
    "        results = POSE.process(image)\n",
    "        angles = np.zeros((1,4))\n",
    "        try:\n",
    "            landmarks = results.pose_landmarks.landmark\n",
    "            \n",
    "            # Get coordinates\n",
    "            left_shoulder = [\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_SHOULDER.value].x*img_h, \n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_SHOULDER.value].y*img_w\n",
    "            ]\n",
    "            left_elbow = [\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_ELBOW.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_ELBOW.value].y*img_w\n",
    "            ]\n",
    "            left_knee = [\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_KNEE.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_KNEE.value].y*img_w\n",
    "            ]\n",
    "            left_hip = [\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_HIP.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.LEFT_HIP.value].y*img_w\n",
    "            ]\n",
    "\n",
    "            right_shoulder = [\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_SHOULDER.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_SHOULDER.value].y*img_w\n",
    "            ]\n",
    "            right_elbow = [\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_ELBOW.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_ELBOW.value].y*img_w\n",
    "            ]\n",
    "            right_knee = [\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_KNEE.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_KNEE.value].y*img_w\n",
    "            ]\n",
    "            right_hip = [\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_HIP.value].x*img_h,\n",
    "                landmarks[MP_POSE.PoseLandmark.RIGHT_HIP.value].y*img_w\n",
    "            ]\n",
    "            \n",
    "            # Calculate angle & Store in (1, 4) vector\n",
    "            angles[0][0] = calculate_angle(left_elbow, left_shoulder, right_shoulder) #angle_1\n",
    "            angles[0][1] = calculate_angle(right_elbow, right_shoulder, left_shoulder)\n",
    "            angles[0][2] = calculate_angle(left_knee, left_hip, right_hip)\n",
    "            angles[0][3] = calculate_angle(right_knee, right_hip, left_hip)         \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        MP_DRAWING.draw_landmarks(\n",
    "            image, results.pose_landmarks, MP_POSE.POSE_CONNECTIONS,\n",
    "            MP_DRAWING.DrawingSpec(color=tuple(reversed((245,117,66))), thickness=2, circle_radius=2), \n",
    "            MP_DRAWING.DrawingSpec(color=tuple(reversed((245,66,230))), thickness=2, circle_radius=2)\n",
    "        )\n",
    "    return image, results, angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# videos = ['01_hipjoint', '02_waist', '03_trapezius']\n",
    "# for video_file in videos:\n",
    "#     clip = VideoFileClip(str(data_path / f'{video_file}.mp4')).without_audio()\n",
    "#     all_angles = []\n",
    "#     all_outputs = []\n",
    "#     for image in tqdm(clip.iter_frames()):\n",
    "#         image_output = image.copy()\n",
    "#         image_output, results, angles = process_mediapipe(image=image_output)\n",
    "#         all_angles.append(angles)\n",
    "#         all_outputs.append(image_output)\n",
    "#     new_clip = concatenate_videoclips([CompositeVideoClip([ImageClip(x, duration=1/clip.fps)]) for x in all_outputs])\n",
    "#     new_video_name = f'{video_file}_gold.mp4'\n",
    "#     new_clip.write_videofile(str(data_path / new_video_name), fps=clip.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def draw_line(mask_img, box, color):\n",
    "#     bg_image = np.repeat(np.zeros_like(mask_img)[:, :, None], 4, axis=2)\n",
    "#     cv2.rectangle(bg_image, box[:2], box[2:], COLOR_DICT[color], 2)\n",
    "#     # bg_mask = (bg_image > 0).sum(2).astype(np.uint8) * 255\n",
    "#     # single_blank = np.zeros((bg_image.shape[0], bg_image.shape[1], 1), dtype=bg_image.dtype)\n",
    "#     # bg_image = np.concatenate((single_blank, bg_image), axis=-1)\n",
    "#     # bg_image[:, :, 0] = bg_mask\n",
    "#     return bg_image\n",
    "\n",
    "# BOX_THRES = 30\n",
    "# COLOR_DICT = {\n",
    "#     'red': (255, 0, 0, 255),\n",
    "#     'green': (0, 255, 0, 255)\n",
    "# }\n",
    "# videos = ['01_hipjoint', '02_waist', '03_trapezius']\n",
    "\n",
    "# boxes = []\n",
    "# for video_file in videos:\n",
    "#     clip = VideoFileClip(str(data_path / f'{video_file}.mp4')).without_audio()\n",
    "#     image = clip.get_frame(0)\n",
    "#     img_h, img_w, _ = image.shape\n",
    "#     image_output = image.copy()\n",
    "#     image_output, results, angles = process_mediapipe(image=image_output)\n",
    "\n",
    "#     mask_img = (results.segmentation_mask > 0.5).astype(np.uint8)\n",
    "#     x, y, w, h = cv2.boundingRect(mask_img)\n",
    "#     box = (\n",
    "#         max(0, x-BOX_THRES),  # width_left\n",
    "#         max(0, y-BOX_THRES),  # height_top\n",
    "#         min(img_w, x+w+BOX_THRES),  # width_right\n",
    "#         min(img_h, y+h+BOX_THRES)  # height_bottom\n",
    "#     )\n",
    "#     boxes.append(box)\n",
    "\n",
    "#     # red_rgba = draw_line(mask_img, box, color='red')\n",
    "#     # red_rgba = cv2.cvtColor(red_rgba, cv2.COLOR_BGRA2RGBA)\n",
    "#     # cv2.imwrite(f'{video_file}_mask_red.png', red_rgba)\n",
    "\n",
    "#     # green_rgba = draw_line(mask_img, box, color='green')\n",
    "#     # green_rgba = cv2.cvtColor(green_rgba, cv2.COLOR_BGRA2RGBA)\n",
    "#     # cv2.imwrite(f'{video_file}_mask_green.png', green_rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(str(data_path / '00_shoulder.mp4'))\n",
    "# (154, 208, 310, 720)\n",
    "clip_resized = clip.resize(height=720) # make the height 360px ( According to moviePy documenation The width is then computed so that the width/height ratio is conserved.)\n",
    "clip_resized.write_videofile(\"00_shoulder_720p.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.crop(x1=50, x2=350, y1=200, y2=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(str(data_path / '00_shoulder_720p.mp4'))\n",
    "clip = clip.crop(x1=40, x2=350, y1=200, y2=720)\n",
    "frame = clip.get_frame(0)\n",
    "img_h, img_w, _ = frame.shape\n",
    "print(frame.shape)\n",
    "plt.imshow(frame)\n",
    "clip.write_videofile(\"00_shoulder_crop_720p.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(str(data_path / '00_shoulder_crop_720p.mp4'))\n",
    "frame = clip.get_frame(0)\n",
    "img_h, img_w, _ = frame.shape\n",
    "print(frame.shape, clip.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_THRES = 30\n",
    "image = frame.copy()\n",
    "image, results, angles = process_mediapipe(image)\n",
    "mask_img = (results.segmentation_mask > 0.5).astype(np.uint8)\n",
    "x, y, w, h = cv2.boundingRect(mask_img)\n",
    "box = (\n",
    "    max(0, x-BOX_THRES),  # width_left\n",
    "    max(0, y-BOX_THRES),  # height_top\n",
    "    min(img_w, x+w+BOX_THRES),  # width_right\n",
    "    min(img_h, y+h+BOX_THRES)  # height_bottom\n",
    ")\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1280 - 310) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(720 - 520) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_outputs = []\n",
    "for image in tqdm(clip.iter_frames()):\n",
    "    image_output = image.copy()\n",
    "    image_output, results, angles = process_mediapipe(image=image_output)\n",
    "    all_outputs.append(image_output)\n",
    "new_clip = concatenate_videoclips([CompositeVideoClip([ImageClip(x, duration=1/clip.fps)]) for x in all_outputs])\n",
    "new_video_name = f'00_shoulder_gold_720p.mp4'\n",
    "new_clip.write_videofile(str(data_path / new_video_name), fps=clip.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOX_THRES = 30\n",
    "image = frame.copy()\n",
    "image, results, angles = process_mediapipe(image)\n",
    "mask_img = (results.segmentation_mask > 0.5).astype(np.uint8)\n",
    "x, y, w, h = cv2.boundingRect(mask_img)\n",
    "box = (\n",
    "    max(0, x-BOX_THRES),  # width_left\n",
    "    max(0, y-BOX_THRES),  # height_top\n",
    "    min(img_w, x+w+BOX_THRES),  # width_right\n",
    "    min(img_h, y+h+BOX_THRES)  # height_bottom\n",
    ")\n",
    "box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = []\n",
    "data = [\n",
    "    ('Ready for \\nthe next set', 'red', 30, 3),\n",
    "    ('3', 'red', 70, 1),\n",
    "    ('2', 'red', 70, 1),\n",
    "    ('1', 'red', 70, 1),\n",
    "]\n",
    "bg_white = np.ones_like(frame) * 255\n",
    "for k, (txt, color, fontsize, duration) in enumerate(data):\n",
    "    txt_clip = TextClip(txt, fontsize=fontsize, color=color, bg_color='transparent').set_pos('center')\n",
    "    bg_clip = ImageClip(frame)\n",
    "    wait_clip = CompositeVideoClip([bg_clip, txt_clip]).set_duration(duration)\n",
    "    wait_clip = wait_clip\n",
    "    clips.append(wait_clip)\n",
    "\n",
    "concat_clip = concatenate_videoclips(clips, method='compose').fadein(1)\n",
    "# concat_clip = concatenate_videoclips([concat_clip, clip], method='compose')\n",
    "new_video_name = f'intermediate.mp4'\n",
    "concat_clip.write_videofile(new_video_name, fps=clip.fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_mask = (red_image > 0).sum(2).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_image = np.repeat(np.zeros_like(mask_img)[:, :, None], 3, axis=2)\n",
    "cv2.rectangle(bg_image, box[:2], box[2:], COLOR_DICT['red'], 2)\n",
    "bg_mask = (bg_image > 0).sum(2).astype(np.uint8)\n",
    "plt.imshow(bg_image)\n",
    "single_blank = np.zeros((bg_image.shape[0], bg_image.shape[1], 1), dtype=bg_image.dtype)\n",
    "bg_image = np.concatenate((single_blank, bg_image), axis=-1)\n",
    "bg_image[:, :, 0] = bg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_image = np.repeat(np.zeros_like(mask_img)[:, :, None], 4, axis=2)\n",
    "color = COLOR_DICT['red']\n",
    "cv2.rectangle(image, box[:2], box[2:], COLOR_DICT['red'], 2)\n",
    "# x = np.repeat(bg_image[:, :, :, None], , axis=2)\n",
    "cv2.imwrite(f'{video_file}_mask_rec_red.png', bg_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "first_img = clip.get_frame(0)\n",
    "\n",
    "pose = mp_pose.Pose(\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5,\n",
    "    model_complexity=2, enable_segmentation=True) #complexity = 0, 1, 2 (2=> more sophisticated results)\n",
    "\n",
    "img = cv2.cvtColor(first_img.copy(), cv2.COLOR_BGR2RGB) #BGR to RGB \n",
    "results = pose.process(img) #pose processing for getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_background(x):\n",
    "    n_channels = 4\n",
    "    img_height, img_width = x.shape\n",
    "    transparent_img = np.zeros((img_height, img_width, n_channels), dtype=np.uint8)\n",
    "    return transparent_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 0.5\n",
    "\n",
    "mask_img = (results.segmentation_mask > thres).astype(np.uint8)\n",
    "bg = draw_background(mask_img)\n",
    "x = np.repeat(mask_img[:, :, None], 3, axis=2)\n",
    "# cv2.imwrite(f'{video_file}_mask.png', x[:, :, :, None])\n",
    "\n",
    "x,y,w,h = cv2.boundingRect(mask_img)\n",
    "print(x,y,w,h)\n",
    "min_coor = (x, y)\n",
    "max_coor = (x+w,y+h)\n",
    "print(\"min:\", min_coor)\n",
    "print(\"max:\", max_coor)\n",
    "\n",
    "\n",
    "# 저장 \n",
    "\n",
    "# red\n",
    "bg_image = np.repeat(np.zeros_like(mask_img)[:, :, None], 4, axis=2)\n",
    "color = tuple(reversed((220,20,60)))\n",
    "# color = (220,20,60)\n",
    "cv2.rectangle(bg_image, min_coor, max_coor, color, 2)\n",
    "# x = np.repeat(bg_image[:, :, :, None], , axis=2)\n",
    "cv2.imwrite(f'{video_file}_mask_rec_red.png', bg_image)\n",
    "\n",
    "# green\n",
    "bg_image = np.repeat( np.zeros_like(mask_img)[:, :, None], 3, axis=2)\n",
    "color = tuple(reversed((50,205,50)))\n",
    "cv2.rectangle(bg_image, min_coor, max_coor, color, 2)\n",
    "\n",
    "bg_mask = (bg_image > 0).sum(2).astype(np.uint8)\n",
    "bg_image = np.concatenate((bg_image, np.zeros((bg_image.shape[0], bg_image.shape[1], 1), dtype=bg_image.dtype)), axis=-1)\n",
    "bg_image[:, :, -1] = bg_mask\n",
    "\n",
    "cv2.imwrite(f'{video_file}_mask_rec_green.png', bg_image)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 6))\n",
    "axes[0].imshow(mask_img, cmap='binary')\n",
    "axes[1].imshow(bg_image[:, :, :3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_video_data(num_repeat=15, num_times=3):\n",
    "    with (data_path / 'video_names.json').open('r') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    video_action_data = {\n",
    "        '00_hipjoint': [('00:19-00:24', num_repeat, num_times), ('00:38-00:44', num_repeat, num_times)],\n",
    "        '01_shoulder': [('00:22-00:26', num_repeat, num_times)],\n",
    "        '02_waist': [('00:22-00:26', num_repeat, num_times)],\n",
    "        '03_trapezius': [('00:17-00:19', num_repeat, num_times), ('00:21-00:22', num_repeat, num_times)],\n",
    "    }\n",
    "\n",
    "    for k in data.keys():\n",
    "        data[k]['acts'] = video_action_data[k]\n",
    "    with (data_path / 'video_data.json').open('w') as file:\n",
    "        json.dump(data, file)\n",
    "\n",
    "add_video_data(num_repeat=5, num_times=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('.').resolve() / 'videos'\n",
    "MP_DRAWING = mp.solutions.drawing_utils\n",
    "MP_DRAWING_STYLE = mp.solutions.drawing_styles\n",
    "MP_POSE = mp.solutions.pose\n",
    "FMT = '%M:%S'\n",
    "\n",
    "with (DATA_PATH / 'video_data.json').open('r') as file: \n",
    "    video_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, CompositeVideoClip, ImageClip, TextClip, VideoClip, concatenate_videoclips, clips_array\n",
    "# from textClip import TextClip\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wait_clip():\n",
    "    # fix the issue if TextClip is not working due to ImageMagic, `convert --version`\n",
    "    # https://github.com/Zulko/moviepy/issues/401#issuecomment-278679961\n",
    "    wait_clips = []\n",
    "    # (text, color, font_size, duration)\n",
    "    data = [\n",
    "        ('Please rest \\nfor 5 seconds', 'black', 25, 4),\n",
    "        ('Ready for \\nthe next set', 'red', 25, 3),\n",
    "        ('3', 'red', 70, 1),\n",
    "        ('2', 'red', 70, 1),\n",
    "        ('1', 'red', 70, 1),\n",
    "    ]\n",
    "    total_wait_time = 0\n",
    "    bg_white = np.ones_like(bg_img) * 255\n",
    "    for k, (txt, color, fontsize, duration) in enumerate(data):\n",
    "        txt_clip = TextClip(txt, fontsize=fontsize, color=color, bg_color='transparent').set_pos('center')\n",
    "        bg = bg_white if k == 0 else bg_img\n",
    "        bg_clip = ImageClip(bg)\n",
    "        wait_clip = CompositeVideoClip([bg_clip, txt_clip]).set_duration(duration)\n",
    "        total_wait_time += duration\n",
    "        if k == 0:\n",
    "            wait_clip = wait_clip.fadein(0.5).fadeout(0.5)\n",
    "            total_wait_time += 1\n",
    "        wait_clips.append(wait_clip)\n",
    "    return concatenate_videoclips(wait_clips), total_wait_time\n",
    "\n",
    "def restart_clip(bg_img):\n",
    "    wait_clips = []\n",
    "    data = [\n",
    "        ('Ready for \\nthe next set', 'red', 720, 3),\n",
    "        ('3', 'red', 70, 1),\n",
    "        ('2', 'red', 70, 1),\n",
    "        ('1', 'red', 70, 1),\n",
    "    ]\n",
    "    bg_white = np.ones_like(bg_img) * 255\n",
    "    for k, (txt, color, fontsize, duration) in enumerate(data):\n",
    "        txt_clip = TextClip(txt, fontsize=fontsize, color=color, bg_color='transparent').set_pos('center')\n",
    "        bg_clip = ImageClip(bg_img)\n",
    "        wait_clip = CompositeVideoClip([bg_clip, txt_clip]).set_duration(duration)\n",
    "        wait_clip = wait_clip.fadein(0.5)\n",
    "        wait_clips.append(wait_clip)\n",
    "    return wait_clip\n",
    "\n",
    "def get_intermediate_count_clip(sub_clip, count):\n",
    "    txt_clip = TextClip(f'{count}', fontsize=70, color='red', bg_color='transparent')\\\n",
    "        .set_pos((0.1, 0.1), relative=True).set_duration(sub_clip.duration)\n",
    "    inter_clip = CompositeVideoClip([sub_clip, txt_clip])\n",
    "    return inter_clip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for video_path in sorted(data_path.glob('*.mp4')):\n",
    "    print(video_path.name)\n",
    "    clip = VideoFileClip(str(video_path)).without_audio()\n",
    "    print(clip.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restart_clip(bg_img):\n",
    "    wait_clips = []\n",
    "    data = [\n",
    "        ('Ready for \\nthe next set', 'red', 720, 3),\n",
    "        ('3', 'red', 70, 1),\n",
    "        ('2', 'red', 70, 1),\n",
    "        ('1', 'red', 70, 1),\n",
    "    ]\n",
    "    bg_white = np.ones_like(bg_img) * 255\n",
    "    for k, (txt, color, fontsize, duration) in enumerate(data):\n",
    "        txt_clip = TextClip(txt, fontsize=fontsize, color=color, bg_color='transparent').set_pos('center')\n",
    "        bg_clip = ImageClip(bg_img)\n",
    "        wait_clip = CompositeVideoClip([bg_clip, txt_clip]).set_duration(duration)\n",
    "        wait_clip = wait_clip.fadein(0.5)\n",
    "        wait_clips.append(wait_clip)\n",
    "    return wait_clip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambient_ai2022-SEYtttOV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0e54cbbf3f76ad0c117a98232f016153fbf525bed90828b9849d372ab6291cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
